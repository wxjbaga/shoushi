from PyQt5.QtWidgets import *
from PyQt5.QtCore import *
from PyQt5.QtGui import *
from widgets import *
from models.yolov5_model import YOLOv5Model
import queue
from thread_worker import VideoWorker
from CameraWorker import CameraWorker
import cv2  # æ³¨æ„ç¡®ä¿å·²ç» import cv2
import os
import traceback
from frcnn import FRCNN
from ssd import SSD
from PIL import Image
import numpy as np
import threading
import torch
from PyQt5.QtCore import QTimer



class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("æ‰‹åŠ¿è¯†åˆ«ç³»ç»Ÿ v1.0")
        self.setMinimumSize(1200, 800)
        self.video_thread = None

        self.cap = None  # è§†é¢‘/æ‘„åƒå¤´å¯¹è±¡
        self.timer = QTimer()  # å®šæ—¶å™¨ï¼Œç”¨äºå¾ªç¯åˆ·æ–°å¸§
        self.video_path = None  # è§†é¢‘æ–‡ä»¶è·¯å¾„


        # åˆå§‹åŒ–UI
        self.init_ui()
        self.init_models()
        self.connect_signals()
        self.write_index = 0  # å½“å‰å†™å…¥çš„è¡Œç´¢å¼•ï¼ˆ0~2ï¼‰

        self.camera_frame_queue = queue.Queue(maxsize=3)
        self.video_frame_queue = queue.Queue(maxsize=3)
        self.video_worker = VideoWorker(self.current_model, self.video_frame_queue)
        self.video_worker.result_ready.connect(self.display_result_frame)
        self.video_worker.performance_ready.connect(self.update_performance_table)

        self.camera_worker = CameraWorker(self.current_model, self.camera_frame_queue)
        self.camera_worker.result_ready.connect(self.display_result_frame)
    def init_ui(self):
        """åˆå§‹åŒ–ç•Œé¢å¸ƒå±€"""
        # ä¸­å¤®éƒ¨ä»¶
        central_widget = QWidget()
        self.setCentralWidget(central_widget)

        # ä¸»å¸ƒå±€
        main_layout = QHBoxLayout(central_widget)
        main_layout.setContentsMargins(5, 5, 5, 5)

        # å·¦ä¾§æ§åˆ¶é¢æ¿
        self.left_panel = ControlPanel()
        self.left_panel.setFixedWidth(300)  # ğŸ”§ è®¾ç½®å›ºå®šå®½åº¦ï¼Œæ¯”å¦‚300px
        main_layout.addWidget(self.left_panel)

        # å³ä¾§æ˜¾ç¤ºåŒºåŸŸ
        self.right_panel = DisplayTabs()
        main_layout.addWidget(self.right_panel, stretch=3)

        # çŠ¶æ€æ 
        self.status_bar = QStatusBar()
        self.setStatusBar(self.status_bar)
        self.status_bar.showMessage("å‡†å¤‡å°±ç»ª", 3000)



    def init_models(self):
        """åˆå§‹åŒ–æ¨¡å‹"""

        # åœ¨ MainWindow çš„ init_models æ–¹æ³•ä¸­

        self.models = {
            "YOLOv5s": YOLOv5Model("yolov5/weights/best.pt"),
            "FasterRCNN": FRCNN(),
            "SSD": SSD()
        }
        for model in self.models.values():
            model.load_model()
        self.current_model = self.models["YOLOv5s"]

    def reset_thread_worker(self, new_model):
        # å…³é—­æ—§çº¿ç¨‹
        if self.video_worker and self.video_worker.isRunning():
            self.video_worker.stop()
            self.video_worker.wait()

        # åˆ›å»ºæ–°çº¿ç¨‹ï¼ˆç¡®ä¿æ¨¡å‹åŒæ­¥ï¼‰
        self.video_worker = VideoWorker(new_model, self.video_frame_queue)
        self.video_worker.result_ready.connect(self.display_result_frame)
        self.camera_worker = CameraWorker(new_model, self.camera_frame_queue)
        self.camera_worker.result_ready.connect(self.display_result_frame)
        self.video_worker.performance_ready.connect(self.update_performance_table)
    def change_model(self, model_name):
        if model_name in self.models:
            self.current_model = self.models[model_name]
            self.reset_thread_worker(self.current_model)
            print(self.video_worker.model)
            self.status_bar.showMessage(f"å·²åˆ‡æ¢æ¨¡å‹: {model_name}", 3000)


    def connect_signals(self):
        """è¿æ¥ä¿¡å·æ§½"""
        # æ¨¡å‹é€‰æ‹©
        self.left_panel.model_selector.currentTextChanged.connect(self.change_model)

        self.left_panel.conf_threshold_changed.connect(self.update_model_conf)
        self.left_panel.iou_threshold_changed.connect(self.update_model_iou)

        # æ‘„åƒå¤´æ§åˆ¶
        self.right_panel.camera_tab.start_btn.clicked.connect(self.start_camera_detection)

        # è§†é¢‘æ§åˆ¶
        self.right_panel.video_tab.open_btn.clicked.connect(self.open_video_dialog)

        # å›¾ç‰‡æ§åˆ¶
        self.right_panel.image_tab.open_btn.clicked.connect(self.open_image_dialog)
        self.right_panel.video_tab.play_btn.clicked.connect(self.play_video)


    def update_model_conf(self, value):
        print(f"[å‚æ•°å˜åŒ–] æ–°ç½®ä¿¡åº¦é˜ˆå€¼: {value}")

        try:
            safe_value = max(0.01, min(0.99, float(value)))

            if isinstance(self.current_model, YOLOv5Model):
                self.current_model.set_thresholds(safe_value,self.current_model.iou_thres, )

            elif getattr(self.current_model, 'is_fasterrcnn', False) or getattr(self.current_model, 'is_ssd', False):
                if not hasattr(self, '_model_lock'):
                    self._model_lock = threading.Lock()
                with self._model_lock:
                    self.current_model.set_thresholds(safe_value,self.current_model.nms_iou )
                    print(f"[âˆš] Faster R-CNN æ–°ç½®ä¿¡åº¦å·²è®¾ç½®ä¸º: {safe_value}")
            QTimer.singleShot(300, self.refresh_results)
        except Exception as e:
            print(f"[é”™è¯¯] æ›´æ–°ç½®ä¿¡åº¦é˜ˆå€¼æ—¶å‡ºé”™: {e}")

    def update_model_iou(self, value):
        print(f"[å‚æ•°å˜åŒ–] æ–°IOUé˜ˆå€¼: {value}")
        try:
            safe_value = max(0.01, min(0.99, float(value)))

            if isinstance(self.current_model, YOLOv5Model):
                self.current_model.set_thresholds(self.current_model.conf_thres, safe_value)

            elif getattr(self.current_model, 'is_fasterrcnn', False) or getattr(self.current_model, 'is_ssd', False):
                if not hasattr(self, '_model_lock'):
                    self._model_lock = threading.Lock()
                with self._model_lock:
                    self.current_model.set_thresholds(self.current_model.confidence, safe_value)
                    print(f"[âˆš] Faster R-CNN æ–°IOUå·²è®¾ç½®ä¸º: {safe_value}")

            QTimer.singleShot(300, self.refresh_results)

        except Exception as e:
            print(f"[é”™è¯¯] æ›´æ–° IOU é˜ˆå€¼æ—¶å‡ºé”™: {e}")

    def open_video_dialog(self):
        """æ‰“å¼€è§†é¢‘æ–‡ä»¶å¯¹è¯æ¡†"""
        options = QFileDialog.Options()
        video_file, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©è§†é¢‘æ–‡ä»¶", "",
            "è§†é¢‘æ–‡ä»¶ (*.mp4 *.avi *.mov);;æ‰€æœ‰æ–‡ä»¶ (*)",
            options=options)

        if video_file:
            if hasattr(self, "cap") and self.cap is not None:
                self.timer.stop()
                self.cap.release()
                self.video_worker.stop()
                self.video_frame_queue.queue.clear()
            self.video_path = video_file
            self.right_panel.video_tab.video_label.setText("è§†é¢‘åŠ è½½æˆåŠŸ")
            self.cap = cv2.VideoCapture(self.video_path)
            if not self.cap.isOpened():
                self.status_bar.showMessage("è§†é¢‘æ–‡ä»¶æ‰“å¼€å¤±è´¥", 3000)
                return

            # æ£€æŸ¥åˆ†è¾¨ç‡ï¼Œè‡ªåŠ¨åˆ¤æ–­æ˜¯å¦éœ€è¦æ—‹è½¬
            w = self.cap.get(cv2.CAP_PROP_FRAME_WIDTH)
            h = self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
            print(w,h)
            self.need_rotate = w < h  # æ¨ªå±æ‹æ‘„è§†é¢‘éœ€è¦æ—‹è½¬
            if not self.cap.isOpened():
                self.status_bar.showMessage("è§†é¢‘æ–‡ä»¶æ‰“å¼€å¤±è´¥", 3000)
                return
            self.right_panel.video_tab.play_btn.setEnabled(True)
            self.status_bar.showMessage(f"å·²æ‰“å¼€è§†é¢‘: {video_file}", 3000)

    def play_video(self):
        if not self.cap:
            return
        if not self.video_worker.isRunning():
            self.video_worker.running = True
            self.video_worker.start()
        # æ–­å¼€æ—§çš„ timer ä¿¡å·è¿æ¥ï¼Œé¿å…é‡å¤è¿æ¥
        try:
            self.timer.timeout.disconnect()
        except Exception:
            pass
        print("1")
        self.timer.timeout.connect(self.update_video_frame)
        self.timer.start(30)

    def update_video_frame(self):
        ret, frame = self.cap.read()
        if not ret:
            self.timer.stop()
            self.cap.release()
            self.video_worker.stop()
            return

        if self.video_frame_queue.qsize() < 3:  # é˜²æ­¢è¿‡å¤šå †ç§¯
            print("[update_camera_frame] putting frame into queue")
            self.video_frame_queue.put(frame.copy())

    def display_result_frame(self, frame,source):
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB).copy()
        img = QImage(rgb.data, rgb.shape[1], rgb.shape[0], QImage.Format_RGB888)

        if source == 'video':
            # æ˜¾ç¤ºåœ¨è§†é¢‘åŒºåŸŸçš„ QLabel ä¸Š
            pix = QPixmap.fromImage(img).scaled(self.right_panel.video_tab.video_label.size(), Qt.KeepAspectRatio)
            self.right_panel.video_tab.video_label.setPixmap(pix)
        elif source == 'camera':
            # æ˜¾ç¤ºåœ¨æ‘„åƒå¤´åŒºåŸŸçš„ QLabel ä¸Š
            pix = QPixmap.fromImage(img).scaled(self.right_panel.camera_tab.video_label.size(), Qt.KeepAspectRatio)
            self.right_panel.camera_tab.video_label.setPixmap(pix)


    # ========== åŸæœ‰æ–¹æ³• ==========
    def start_camera_detection(self):
        btn = self.right_panel.camera_tab.start_btn

        if btn.text() == "å¼€å¯æ‘„åƒå¤´":
            # æ‰“å¼€æ‘„åƒå¤´
            self.cap = cv2.VideoCapture(0)
            if not self.cap.isOpened():
                self.status_bar.showMessage("æ— æ³•æ‰“å¼€æ‘„åƒå¤´", 3000)
                return
            # å¯åŠ¨æ¨ç†çº¿ç¨‹
            if not self.camera_worker.isRunning():
                self.camera_worker.running = True
                self.camera_worker.start()
            # åˆ‡æ¢æŒ‰é’®çŠ¶æ€
            btn.setText("å…³é—­æ‘„åƒå¤´")

            # æ–­å¼€ä¹‹å‰çš„å®šæ—¶å™¨ç»‘å®šï¼Œé˜²æ­¢é‡å¤ç»‘å®š
            try:
                self.timer.timeout.disconnect()
            except Exception:
                pass

            # æ¯30msè¯»å–ä¸€å¸§é€å…¥æ¨ç†çº¿ç¨‹
            self.timer.timeout.connect(self.update_camera_frame)
            self.timer.start(30)
            self.status_bar.showMessage("æ‘„åƒå¤´å·²å¼€å¯", 2000)

        else:
            # åœæ­¢æ‘„åƒå¤´ä¸çº¿ç¨‹
            self.timer.stop()
            if self.cap:
                self.cap.release()
                self.cap = None
            self.camera_worker.stop()

            # æ¸…ç©ºç”»é¢ä¸çŠ¶æ€
            self.right_panel.camera_tab.video_label.clear()
            btn.setText("å¼€å¯æ‘„åƒå¤´")
            self.status_bar.showMessage("æ‘„åƒå¤´å·²å…³é—­", 2000)

    def update_camera_frame(self):
        if not self.cap:
            print("[update_camera_frame] cap is None")
            return
        ret, frame = self.cap.read()
        if not ret:
            print("[update_camera_frame] frame not received")
            self.timer.stop()
            self.cap.release()
            self.cap = None
            self.camera_worker.stop()
            self.status_bar.showMessage("æ‘„åƒå¤´è¯»å–å¤±è´¥", 3000)
            return
        print("[update_camera_frame] got frame")

        print(self.camera_frame_queue.qsize())
        if self.camera_frame_queue.qsize() < 3:
            print("[update_camera_frame] putting frame into queue")
            self.camera_frame_queue.put(frame.copy())
        else:
            print("[update_camera_frame] queue full, skipping")
    def open_image_dialog(self):
        try:
            options = QFileDialog.Options()
            image_file, _ = QFileDialog.getOpenFileName(
                self, "é€‰æ‹©å›¾ç‰‡æ–‡ä»¶", "",
                "å›¾ç‰‡æ–‡ä»¶ (*.jpg *.png *.bmp);;æ‰€æœ‰æ–‡ä»¶ (*)",
                options=options)

            if not image_file:
                return

            frame = cv2.imread(image_file)
            self.current_image = frame.copy()
            # åˆ¤æ–­æ˜¯å¦æ˜¯ä½¿ç”¨çš„ Faster R-CNN æ¨¡å‹
            if hasattr(self.current_model, 'is_fasterrcnn') and self.current_model.is_fasterrcnn or hasattr(self.current_model, 'is_ssd') and self.current_model.is_ssd:
                # OpenCV å›¾åƒ -> PIL
                image_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                results, image_for_draw = self.current_model.predict(image_pil)
                frame = self.current_model.draw_results(image_for_draw, results)

                if isinstance(results, list) and len(results) > 0:
                    detections = results[0]
                    if isinstance(detections, torch.Tensor):
                        detections = detections.cpu().numpy()
                    if detections.size > 0:
                        if detections.shape[1] == 6:  # SSD/FasterRCNN æ ¼å¼
                            # æœ‰äº›æ˜¯ [x1, y1, x2, y2, score, class_id]ï¼Œæœ‰äº›æ˜¯ [x1, y1, x2, y2, class_id, score]
                            if detections[0, 4] < 1 and detections[0, 5] >= 1:  # [x1, y1, x2, y2, score, class_id]
                                confidences = detections[:, 4]
                            else:  # [x1, y1, x2, y2, class_id, score]
                                confidences = detections[:, 5]
                            max_conf = float(confidences.max())
                        else:
                            max_conf = 0.0
                    else:
                        max_conf = 0.0
                else:
                    max_conf = 0.0

                # if not isinstance(frame, np.ndarray):
                #     frame = np.array(frame)
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)


            else:
                if frame is None:
                    QMessageBox.critical(self, "é”™è¯¯", "å›¾ç‰‡è¯»å–å¤±è´¥ï¼Œå¯èƒ½æ˜¯æ–‡ä»¶è·¯å¾„æˆ–æ ¼å¼é”™è¯¯")
                    return
                # === æ¨¡å‹é¢„æµ‹ä¸ç»˜å›¾ ===
                results = self.current_model.predict(frame)
                if isinstance(results, torch.Tensor):
                    result = results.cpu().numpy()  # è½¬æˆ numpy
                if len(result) > 0:
                    confidences = result[:, 4]  # ç¬¬ 5 åˆ—æ˜¯ç½®ä¿¡åº¦
                    max_conf = float(confidences.max())
                else:
                    max_conf = 0.0
                if results is None:
                    QMessageBox.critical(self, "é”™è¯¯", "æ¨¡å‹é¢„æµ‹å¤±è´¥")
                    return
                # ä¼ è¿›å»
                frame = self.current_model.draw_results(frame, results)

            if frame is None or not hasattr(frame, "shape"):
                QMessageBox.critical(self, "é”™è¯¯", "é¢„æµ‹ç»“æœä¸ºç©ºï¼Œæ— æ³•æ˜¾ç¤º")
                return
            # è·å–æ¨¡å‹åç§°
            if hasattr(self.current_model, 'is_fasterrcnn') and self.current_model.is_fasterrcnn:
                model_name = "Faster R-CNN"
            elif hasattr(self.current_model, 'is_ssd') and self.current_model.is_ssd:
                model_name = "SSD"
            else:
                model_name = "YOLOv5"
            # === æ˜¾ç¤ºå›¾åƒ ===
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            h, w, ch = frame.shape
            bytes_per_line = ch * w
            qimg = QImage(frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
            pixmap = QPixmap.fromImage(qimg).scaled(
                self.right_panel.image_tab.image_label.size(), Qt.KeepAspectRatio)

            self.right_panel.image_tab.image_label.setPixmap(pixmap)

            self.update_confidence_in_table(model_name,max_conf)
            self.status_bar.showMessage(f"å·²è¯†åˆ«å›¾ç‰‡: {image_file}", 3000)

        except Exception as e:
            error_msg = traceback.format_exc()
            print(f"[CRASH] å›¾ç‰‡è¯†åˆ«é”™è¯¯:\n{error_msg}")

            # æ˜¾ç¤ºç®€åŒ–çš„é”™è¯¯ä¿¡æ¯ç»™ç”¨æˆ·
            error_type = type(e).__name__
            error_location = traceback.extract_tb(e.__traceback__)[-1]  # è·å–æœ€åä¸€ä¸ªé”™è¯¯ä½ç½®
            user_friendly_msg = (
                f"ç¨‹åºå‡ºé”™:\n"
                f"é”™è¯¯ç±»å‹: {error_type}\n"
                f"é”™è¯¯ä½ç½®: {error_location.filename} ç¬¬ {error_location.lineno} è¡Œ\n"
                f"é”™è¯¯è¯¦æƒ…: {str(e)}"
            )

            QMessageBox.critical(self, "å¼‚å¸¸", user_friendly_msg)

    def update_confidence_in_table(self, model_name: str,confidence):
        row = self.write_index
        self.left_panel.metrics_table.setItem(row, 0, QTableWidgetItem(model_name))
        item = QTableWidgetItem(f"{confidence:.3f}")
        # å‡è®¾ç½®ä¿¡åº¦æ”¾å·¦ä¾§è¡¨æ ¼ç¬¬0è¡Œç¬¬1åˆ—ï¼Œè°ƒæ•´ç´¢å¼•å¯¹åº”ä½ çš„è¡¨æ ¼
        self.left_panel.metrics_table.setItem(row, 1, item)
        self.write_index = (self.write_index + 1) % 3  # å¾ªç¯ä½¿ç”¨ä¸‰è¡Œ

    def update_performance_table(self, fps, avg_conf):
        if hasattr(self.current_model, 'is_fasterrcnn') and self.current_model.is_fasterrcnn:
            model_name = "Faster R-CNN"
        elif hasattr(self.current_model, 'is_ssd') and self.current_model.is_ssd:
            model_name = "SSD"
        else:
            model_name = "YOLOv5"
        row = self.write_index
        self.left_panel.metrics_table.setItem(row, 0, QTableWidgetItem(model_name))
        self.left_panel.metrics_table.setItem(row, 2, QTableWidgetItem(f"{fps:.2f}"))  # å‡è®¾ç¬¬2åˆ—æ˜¯FPS
        self.left_panel.metrics_table.setItem(row, 1, QTableWidgetItem(f"{avg_conf:.2f}"))  # å‡è®¾ç¬¬3åˆ—æ˜¯å¹³å‡ç½®ä¿¡åº¦
        self.write_index = (self.write_index + 1) % 3  # å¾ªç¯ä½¿ç”¨ä¸‰è¡Œ

    def refresh_results(self):
        if not hasattr(self, "current_image") or self.current_image is None:
            return
        try:
            frame = self.current_image.copy()
            # å¤„ç† Faster R-CNN æ¨¡å‹
            if hasattr(self.current_model, 'is_fasterrcnn') and self.current_model.is_fasterrcnnor or hasattr(self.current_model, 'is_ssd') and self.current_model.is_ssd:
                # OpenCV å›¾åƒ -> PIL
                image_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                results, image_for_draw = self.current_model.predict(image_pil)
                if results is None:
                    QMessageBox.critical(self, "é”™è¯¯", "Faster R-CNN æ¨¡å‹é¢„æµ‹å¤±è´¥")
                    return
                frame = self.current_model.draw_results(image_for_draw, results)
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # è½¬æ¢å›BGRä¿æŒä¸€è‡´æ€§
            # å¤„ç† YOLOv5 æˆ–å…¶ä»–æ¨¡å‹
            else:
                self.current_results = self.current_model.predict(frame)

                if self.current_results is None:
                    QMessageBox.critical(self, "é”™è¯¯", "æ¨¡å‹é¢„æµ‹å¤±è´¥")
                    return

                frame = self.current_model.draw_results(frame, self.current_results)
            # ç»Ÿä¸€æ˜¾ç¤ºå¤„ç†
            if frame is None or not hasattr(frame, "shape"):
                QMessageBox.critical(self, "é”™è¯¯", "é¢„æµ‹ç»“æœä¸ºç©ºï¼Œæ— æ³•æ˜¾ç¤º")
                return

            # è½¬æ¢ä¸ºRGBæ ¼å¼æ˜¾ç¤º
            display_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            h, w, ch = display_frame.shape
            bytes_per_line = ch * w
            qimg = QImage(display_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
            pixmap = QPixmap.fromImage(qimg).scaled(
                self.right_panel.image_tab.image_label.size(),
                Qt.KeepAspectRatio,
                Qt.SmoothTransformation)

            self.right_panel.image_tab.image_label.setPixmap(pixmap)

        except Exception as e:
            error_msg = traceback.format_exc()
            print(f"[CRASH] åˆ·æ–°ç»“æœé”™è¯¯:\n{error_msg}")
            QMessageBox.critical(self, "é”™è¯¯", f"åˆ·æ–°ç»“æœæ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")

